{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff42810-81e2-49bc-bac7-51422b4d865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "\n",
    "import io\n",
    "import pickle\n",
    "import gc\n",
    "import statistics\n",
    "import holidays\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, cross_val_score, GridSearchCV\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import mlflow\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3c5c5e-6836-420b-a2cc-c36b5fee9fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preparation' from '/srv/scratch/Pugachenko/for_Tomsk/pipeline/streamlit/data_preparation.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импорт скрипта по обработке данных и формирования таблиц с Q,T и праздниками\n",
    "#import data_preparation\n",
    "#importlib.reload(data_preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a88aae0b-c699-4984-96c4-3f96e69d1a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/srv/scratch/Pugachenko/for_Tomsk/pipeline/streamlit/data_preparation.py\", line 8, in <module>\n",
      "    import holidays\n",
      "ModuleNotFoundError: No module named 'holidays'\n"
     ]
    }
   ],
   "source": [
    "!python3 'data_preparation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f141997-779f-4936-b131-8591688691dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт функций сглаживания Q\n",
    "import smoothfunction \n",
    "importlib.reload(smoothfunction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc3eaef-6d31-4e64-a791-8174a270a035",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'streamlit' has no attribute 'title' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n",
      "File \u001b[0;32m/srv/scratch/Pugachenko/for_Tomsk/pipeline/streamlit/streamlit.py:183\u001b[0m\n\u001b[1;32m    180\u001b[0m     iplot(fig, show_link\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m####################################################################\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m st\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTomsk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# загружаем словарь номер объекта : функция сглаживания \u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmooth_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'streamlit' has no attribute 'title' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72db916f-dec7-4566-88c0-c142cd2ce57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 15:15:12.012 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/conda/envs/pugachenko/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title('My first app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f4cf7-e920-4418-9e5a-cd2441608f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт функций сглаживания Q\n",
    "import smoothfunction \n",
    "importlib.reload(smoothfunction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "530cef81-ce53-40c3-b546-a4109a195a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем словарь номер объекта : название объекта (формируется словарь при выполнении скрипта data_preparation.py)\n",
    "with open('id_dict.pkl', 'rb') as f:\n",
    "    id_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e80e9f1-92f5-47df-815e-e8c9997360fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем словарь номер объекта : функция сглаживания \n",
    "with open('smooth_dict.pkl', 'rb') as f:\n",
    "    smooth_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af67b12-4747-4fb8-a890-474260f28664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_T = pd.read_csv('df_T_w_old.csv', index_col = 'Date', parse_dates = True)\n",
    "#for col in df_T.columns:\n",
    " #   df_T = df_T.rename(columns = {col:int(col)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5212399-368c-49b6-a34c-3889b6027e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Q = pd.read_csv('df_Q_w.csv', index_col = 'Date', parse_dates = True)\n",
    "for col in df_Q.columns:\n",
    "    df_Q = df_Q.rename(columns = {col:int(col)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28b441-0b1d-466a-bd08-7cf6915a60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays = pd.read_csv('df_holidays.csv')\n",
    "df_holidays['Date'] = pd.to_datetime(df_holidays['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bc65d-1d51-49c7-9c0e-1dd836a200e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9b084-276a-4283-824c-ba65d72803af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_date = '2022-01-01 01:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfb24a-41e5-4abf-97df-f3597953529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f48db95-4ec0-4997-9402-7fed3bf44773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'24': 'ГРС-1 г.Томск',\n",
       " '1': 'ГРС-1 г.Кемерово',\n",
       " '2': 'ГРС-2 г.Кемерово',\n",
       " '3': 'г.Новокузнецк ГРС-2',\n",
       " '4': 'г.Новокузнецк ГРС-1',\n",
       " '7': 'ГРС-6 г.Новосибирск',\n",
       " '8': 'ГРС-2 г.Новосибирск',\n",
       " '10': 'ГРС-5 г.Новосибирск',\n",
       " '21': 'ГРС-1 г.Нижневартовск',\n",
       " '37': 'ГРС-1 г.Барнаул',\n",
       " '38': 'ГРС-2 г.Барнаул',\n",
       " '79': 'ГРС-2 г.Томск',\n",
       " '16': 'ГРС-4 г.Томск',\n",
       " '142': '12,6 км отв. к ГРС Омск-1',\n",
       " '1+2': 'ГРС-1 + ГРС-2 г.Томск',\n",
       " '7+8': 'ГРС-2 + ГРС-6 г.Нижневартовск',\n",
       " '37+38': 'ГРС-1 + ГРС-2 г.Барнаул',\n",
       " '24+79': 'ГРС-1 + ГРС-2 г.Томск'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f54e9ba1-6e6c-46a6-a557-dd5395bd746a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(id_dict\u001b[38;5;241m.\u001b[39mget(key[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mГРС-4 г.Томск\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "print(id_dict.get(key['ГРС-4 г.Томск']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79681c0e-fcd4-4ca3-bfd2-f3ea3f3f8089",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dict.keys() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m id_dict\u001b[38;5;241m.\u001b[39mkeys([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mГРС-4 г.Томск\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: dict.keys() takes no arguments (1 given)"
     ]
    }
   ],
   "source": [
    "id_dict.keys(['ГРС-4 г.Томск'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0bc8efc-22b4-4141-a3d5-256bed73ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(id_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9779f9dc-163b-48ab-91a9-9513fc20315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(list(id_dict.keys())[list(id_dict.values()).index('ГРС-4 г.Томск')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98698166-e1a0-42ad-b36a-efc83cd76e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт функций сглаживания Q\n",
    "import features_created \n",
    "importlib.reload(features_created);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33517023-1f06-4908-a576-5d5320e0fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays = pd.read_csv('df_holidays.csv')\n",
    "df_holidays['Date'] = pd.to_datetime(df_holidays['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad7e09f5-6f89-4763-beed-f76496221764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт функций сглаживания Q\n",
    "import smoothfunction \n",
    "importlib.reload(smoothfunction);\n",
    "\n",
    "import create_features \n",
    "importlib.reload(create_features);\n",
    "\n",
    "import train_and_pred\n",
    "importlib.reload(train_and_pred);\n",
    "\n",
    "# загружаем словарь номер объекта : функция сглаживания \n",
    "with open('smooth_dict.pkl', 'rb') as f:\n",
    "    smooth_dict = pickle.load(f)\n",
    "\n",
    "# загружаем словарь номер объекта : название объекта (формируется словарь при выполнении скрипта data_preparation.py)\n",
    "with open('id_dict.pkl', 'rb') as f:\n",
    "    id_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "954c6c9f-c232-46ec-8d92-c8a716176e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Q = pd.read_csv('df_Q_w.csv', index_col = 'Date', parse_dates = True)\n",
    "   \n",
    "df_T = pd.read_csv('df_T_w.csv', index_col = 'Date', parse_dates = True)\n",
    "\n",
    "df_holidays = pd.read_csv('df_holidays.csv')\n",
    "df_holidays['Date'] = pd.to_datetime(df_holidays['Date'])\n",
    "\n",
    "import smoothfunction \n",
    "importlib.reload(smoothfunction);\n",
    "\n",
    "import create_features \n",
    "importlib.reload(create_features);\n",
    "\n",
    "import train_and_pred\n",
    "importlib.reload(train_and_pred);\n",
    "\n",
    "# загружаем словарь номер объекта : название объекта (формируется словарь при выполнении скрипта data_preparation.py)\n",
    "with open('id_dict.pkl', 'rb') as f:\n",
    "    id_dict = pickle.load(f)\n",
    "\n",
    "# загружаем словарь номер объекта : функция сглаживания \n",
    "with open('smooth_dict.pkl', 'rb') as f:\n",
    "    smooth_dict = pickle.load(f)\n",
    "\n",
    "trig = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ecfbe51b-4a1d-4ee8-a48f-b4b5719be90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non_scaling_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(models_dir)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, pred_len\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m# прогноз на 10 суток с сохранением 120 моделей (по одной на каждую двухчасовку)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m         train_and_pred\u001b[38;5;241m.\u001b[39mtrain_model_and_save(df_Q[\u001b[38;5;28mid\u001b[39m], df_T[\u001b[38;5;28mid\u001b[39m], df_holidays, \u001b[38;5;28mid\u001b[39m, i, pred_start_date, models_dir)\n",
      "File \u001b[0;32m/srv/scratch/Pugachenko/for_Tomsk/pipeline/streamlit/train_and_pred.py:49\u001b[0m, in \u001b[0;36mtrain_model_and_save\u001b[0;34m(ser_Q, ser_T, df_holidays, id, i, date_start, models_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m y_scaler \u001b[38;5;241m=\u001b[39m RobustScaler()\n\u001b[1;32m     47\u001b[0m y_train_norm \u001b[38;5;241m=\u001b[39m y_scaler\u001b[38;5;241m.\u001b[39mfit_transform(y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 49\u001b[0m X_train_norm \u001b[38;5;241m=\u001b[39m X_scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train\u001b[38;5;241m.\u001b[39mdrop(non_scaling_features, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     50\u001b[0m X_train_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[X_train_norm, X_train[non_scaling_features]]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# обучение модели\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'non_scaling_features' is not defined"
     ]
    }
   ],
   "source": [
    "pred_len = 3\n",
    "id = '2'\n",
    "pred_start_date = pd.to_datetime('2022-01-01', format = '%Y-%m-%d')\n",
    "model = HuberRegressor()\n",
    "models_dir = f'saved_models_{id}' # место хранения моделей\n",
    "if not os.path.exists(models_dir): # cоздается директорию для сохранения моделей, если она еще не существует\n",
    "    os.makedirs(models_dir)\n",
    "    \n",
    "for i in range(1, pred_len*12+1): # прогноз на 10 суток с сохранением 120 моделей (по одной на каждую двухчасовку)\n",
    "        train_and_pred.train_model_and_save(df_Q[id], df_T[id], df_holidays, id, i, pred_start_date, models_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdbe5041-b1ea-474a-ab5e-5851591645a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2014-01-01 01:00:00    63.5000\n",
       "2014-01-01 03:00:00    63.5000\n",
       "2014-01-01 05:00:00    63.5000\n",
       "2014-01-01 07:00:00    63.5000\n",
       "2014-01-01 09:00:00    62.4100\n",
       "                        ...   \n",
       "2024-06-30 15:00:00     7.9965\n",
       "2024-06-30 17:00:00     6.7822\n",
       "2024-06-30 19:00:00     7.0153\n",
       "2024-06-30 21:00:00     7.0537\n",
       "2024-06-30 23:00:00     6.7853\n",
       "Name: 24, Length: 46008, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Q['24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "210fd84d-7f1d-423e-922b-1080bd7ae787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = create_features.create_features(df_Q[id], df_T[id], df_holidays, id, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a607fa-5f2c-4ff1-a49d-c2c62f71893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_lag(df_features, lag):\n",
    "    # лаговые переменные\n",
    "    df_features[f'Q_lag_{168}'] = df_features['Q'].shift(168)\n",
    "    df_features[f'T_lag_{168}'] = df_features['T_Value'].shift(168)\n",
    "    df_features[f'Q_lag_{lag}'] = df_features['Q'].shift(lag)\n",
    "    df_features[f'T_lag_{lag}'] = df_features['T_Value'].shift(lag)\n",
    "    if lag <= 84:\n",
    "        df_features[f'Q_lag_{84}'] = df_features['Q'].shift(84)\n",
    "        df_features[f'T_lag_{84}'] = df_features['T_Value'].shift(84)\n",
    "\n",
    "     # удаление строк с сильно падающими значениями газопотребления вплоть до нулевых\n",
    "    mean_val = df_features['Q'].mean()\n",
    "    min_val = mean_val*0.1\n",
    "    \n",
    "    df_features = df_features[\n",
    "        ~(\n",
    "            (df_features['Q'] < min_val) | \\\n",
    "            (df_features['Q_lag_-168'] < min_val) | \\\n",
    "            (df_features['Q_lag_-84'] < min_val) | \\\n",
    "            (df_features['Q_lag_-36'] < min_val)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "       # return df_features\n",
    "    # удаление строк с NaN значениями после добавления лагов\n",
    "    df_features = df_features.dropna()\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb9726-e4ed-43ba-a3d5-8ecea62396eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_without_lag(df_Q, df_T, df_holidays, id, trig = False):\n",
    "    \n",
    "    # добавление в датафрейм Q, T\n",
    "    df_features = df_Q[[id]] #.loc[df_gas_smooth.index > pd.to_datetime('2022-01-01')]\n",
    "    df_features.rename({id : 'Q'}, axis = 1, inplace = True)\n",
    "    \n",
    "    # Применяем функцию сглаживания из smoothfunction.py для соответствующего id\n",
    "    #df_features.loc[df_features.index < input_date, 'Q'] = smooth_dict[id](df_features.loc[df_features.index < input_date,'Q'])\n",
    "    df_features['Q'] = smooth_dict[id](df_features['Q'])\n",
    "    \n",
    "    df_features['T_Value'] = df_T[[id]]#.loc[df_temp.index > pd.to_datetime('2022-01-01')]\n",
    "    \n",
    "    # добавление в датафрейм даты и часа\n",
    "    df_features['Datetime'] = df_features.index\n",
    "    df_features['Hour'] = df_features.Datetime.dt.hour\n",
    "    df_features['Datetime'] = df_features.Datetime.dt.date\n",
    "    df_features['Datetime'] = pd.to_datetime(df_features['Datetime'], format = '%Y-%m-%d')\n",
    "    # добавление в датафрейм временных признаков\n",
    "    df_features['day_of_week'] = df_features.Datetime.dt.day_of_week\n",
    "    df_features['month'] = df_features.Datetime.dt.month\n",
    "   \n",
    "    ### добавление праздников\n",
    "    df_features = df_features.merge(df_holidays, how = 'left', left_on = 'Datetime', right_on = 'Date')\n",
    "    df_features.drop(['Date'], axis = 1, inplace = True)\n",
    "    df_features['holiday'] = df_features['holiday'].fillna(0)\n",
    "\n",
    "    # дата в качестве индекса\n",
    "    df_features.index = pd.to_datetime(df_features['Datetime'].astype(str).str.cat(df_features['Hour'].astype(str)+':00:00',sep=\" \"), format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Работа с сезонами\n",
    "    if trig == True:\n",
    "        df_features[\"month_sin\"] = sin_transformer(12).fit_transform(df_features['month'])\n",
    "        df_features[\"month_cos\"] = cos_transformer(12).fit_transform(df_features['month'])\n",
    "        df_features = df_features.drop(['month'], axis = 1)\n",
    "    else:   \n",
    "        df_features = pd.get_dummies(df_features, columns = ['month'], dtype = int)\n",
    "        df_features.drop(['month_12'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # Работа с днями недели\n",
    "    if trig == True:\n",
    "        df_features[\"dow_sin\"] = sin_transformer(7).fit_transform(df_features['day_of_week'])\n",
    "        df_features[\"dow_cos\"] = cos_transformer(7).fit_transform(df_features['day_of_week'])\n",
    "        df_features = df_features.drop(['day_of_week'], axis = 1)\n",
    "    else:\n",
    "        df_features = pd.get_dummies(df_features, columns = ['day_of_week'], dtype = int)\n",
    "        df_features.drop(['day_of_week_0'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # Работа с часами\n",
    "    if trig == True:\n",
    "        df_features[\"hour_sin\"] = sin_transformer(12).fit_transform(df_features['Hour'])\n",
    "        df_features[\"hour_cos\"] = cos_transformer(12).fit_transform(df_features['Hour'])\n",
    "        df_features = df_features.drop(['Hour'], axis = 1)\n",
    "    else:   \n",
    "        df_features = pd.get_dummies(df_features, columns = ['Hour'], dtype = int)\n",
    "        df_features.drop(['Hour_1'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # дата в качестве индекса\n",
    "    df_features.drop(['Datetime'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "   \n",
    "  \n",
    "    ############# Нам неизвестна температура после 2023 года, обрежем пока эти данные ############\n",
    "    df_features = df_features[df_features.index < '2023-01-01']\n",
    "   \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782edad-a2f0-42c0-a1e8-2a99a961c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2efa1336-7480-47c3-8adf-42c19a47bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(((x - 1) / period) * 2 * np.pi))\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(((x - 1) / period) * 2 * np.pi))\n",
    "    \n",
    "def create_features_without_lag(ser_Q, ser_T, df_holidays, id, trig = False):\n",
    "    \n",
    "    # добавление в датафрейм Q, T\n",
    "    df_features = pd.DataFrame(ser_Q)\n",
    "    df_features.rename(columns = {id:'Q'}, inplace = True)\n",
    "      \n",
    "    df_features['T_Value'] = ser_T\n",
    "    \n",
    "    # добавление в датафрейм даты и часа\n",
    "    df_features['Datetime'] = df_features.index\n",
    "    df_features['Hour'] = df_features.Datetime.dt.hour\n",
    "    df_features['Datetime'] = df_features.Datetime.dt.date\n",
    "    df_features['Datetime'] = pd.to_datetime(df_features['Datetime'], format = '%Y-%m-%d')\n",
    "    # добавление в датафрейм временных признаков\n",
    "    df_features['day_of_week'] = df_features.Datetime.dt.day_of_week\n",
    "    df_features['month'] = df_features.Datetime.dt.month\n",
    "   \n",
    "    ### добавление праздников\n",
    "    df_features = df_features.merge(df_holidays, how = 'left', left_on = 'Datetime', right_on = 'Date')\n",
    "    df_features.drop(['Date'], axis = 1, inplace = True)\n",
    "    df_features['holiday'] = df_features['holiday'].fillna(0)\n",
    "\n",
    "    # дата в качестве индекса\n",
    "    df_features.index = pd.to_datetime(df_features['Datetime'].astype(str).str.cat(df_features['Hour'].astype(str)+':00:00',sep=\" \"), format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Работа с сезонами\n",
    "    if trig == True:\n",
    "        df_features[\"month_sin\"] = sin_transformer(12).fit_transform(df_features['month'])\n",
    "        df_features[\"month_cos\"] = cos_transformer(12).fit_transform(df_features['month'])\n",
    "        df_features = df_features.drop(['month'], axis = 1)\n",
    "    else:   \n",
    "        df_features = pd.get_dummies(df_features, columns = ['month'], dtype = int)\n",
    "        df_features.drop(['month_12'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # Работа с днями недели\n",
    "    if trig == True:\n",
    "        df_features[\"dow_sin\"] = sin_transformer(7).fit_transform(df_features['day_of_week'])\n",
    "        df_features[\"dow_cos\"] = cos_transformer(7).fit_transform(df_features['day_of_week'])\n",
    "        df_features = df_features.drop(['day_of_week'], axis = 1)\n",
    "    else:\n",
    "        df_features = pd.get_dummies(df_features, columns = ['day_of_week'], dtype = int)\n",
    "        df_features.drop(['day_of_week_0'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # Работа с часами\n",
    "    if trig == True:\n",
    "        df_features[\"hour_sin\"] = sin_transformer(12).fit_transform(df_features['Hour'])\n",
    "        df_features[\"hour_cos\"] = cos_transformer(12).fit_transform(df_features['Hour'])\n",
    "        df_features = df_features.drop(['Hour'], axis = 1)\n",
    "    else:   \n",
    "        df_features = pd.get_dummies(df_features, columns = ['Hour'], dtype = int)\n",
    "        df_features.drop(['Hour_1'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "    \n",
    "    # дата в качестве индекса\n",
    "    df_features.drop(['Datetime'], axis = 1, inplace = True) # чтоб не было dummy variable trap\n",
    "     \n",
    "    return df_features\n",
    "\n",
    "# lag измеряется в точках (для 10 дней это 120, для 1 дня это 12, для 2х часов - 1)\n",
    "def create_features_lag(df_features_without_lag, lag):\n",
    "    # лаговые переменные\n",
    "    df_features_without_lag[f'Q_lag_{2*lag}'] = df_features_without_lag['Q'].shift(lag)\n",
    "    df_features_without_lag[f'T_lag_{2*lag}'] = df_features_without_lag['T_Value'].shift(lag)\n",
    "    if lag <= 84:\n",
    "       df_features_without_lag[f'Q_lag_{168}'] = df_features_without_lag['Q'].shift(84)\n",
    "       df_features_without_lag[f'T_lag_{168}'] = df_features_without_lag['T_Value'].shift(84)\n",
    "    else:\n",
    "        df_features_without_lag[f'Q_lag_{336}'] = df_features_without_lag['Q'].shift(168)\n",
    "        df_features_without_lag[f'T_lag_{336}'] = df_features_without_lag['T_Value'].shift(168)\n",
    "    \n",
    "    # удаление строк с NaN значениями после добавления лагов\n",
    "    df_features_without_lag = df_features_without_lag.dropna()\n",
    "    \n",
    "    # обработка строк с сильно падающими значениями газопотребления вплоть до нулевых\n",
    "    mean_val = df_features_without_lag['Q'].mean()\n",
    "    min_val = mean_val*0.05\n",
    "    \n",
    "    if lag <= 84:\n",
    "        df_features_without_lag = df_features_without_lag[\n",
    "            ~(\n",
    "                (df_features_without_lag['Q'] < min_val) | \\\n",
    "                (df_features_without_lag['Q_lag_168'] < min_val) | \\\n",
    "                (df_features_without_lag[f'Q_lag_{2*lag}'] < min_val)\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        df_features_without_lag = df_features_without_lag[\n",
    "            ~(\n",
    "                (df_features_without_lag['Q'] < min_val) | \\\n",
    "                (df_features_without_lag['Q_lag_336'] < min_val) | \\\n",
    "                (df_features_without_lag[f'Q_lag_{2*lag}'] < min_val)\n",
    "            )\n",
    "        ]\n",
    "        #df = pd.DataFrame()\n",
    "        df = df_features_without_lag.copy()\n",
    "        df_features_without_lag = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cdcbcef1-da7b-4396-bf87-ef34d120e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_save(df_features_without_lag, id, i, date_start, models_dir):\n",
    "    trig = False\n",
    "    if trig == False:\n",
    "        non_scaling_features = ['holiday',\n",
    "                            'month_1', 'month_2', 'month_3',\n",
    "           'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
    "           'month_10', 'month_11', \n",
    "                            'day_of_week_1', 'day_of_week_2',\n",
    "           'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6',\n",
    "           'Hour_3', 'Hour_5', 'Hour_7', 'Hour_9', 'Hour_11', 'Hour_13',\n",
    "           'Hour_15', 'Hour_17', 'Hour_19', 'Hour_21', 'Hour_23']\n",
    "    if trig == True:\n",
    "        non_scaling_features = ['holiday','month_sin','month_cos','dow_sin','dow_cos','hour_sin','hour_cos']\n",
    "\n",
    "    #scaling_features = list(set(list(df_features.columns)) - set(non_scaling_features))\n",
    "    \n",
    "    date_target = date_start - pd.Timedelta(hours=2)\n",
    "\n",
    "    # экстракция признаков из временного ряда\n",
    "    df_features = create_features_lag(df_features_without_lag, i) \n",
    "        \n",
    "    # определение тренировочного набора\n",
    "    train_size = len(df_features.loc[df_features.index <= date_target])\n",
    "    train = df_features.iloc[:train_size]\n",
    "    \n",
    "    y_train = train['Q']  \n",
    "    X_train = train.drop('Q', axis = 1)\n",
    "    \n",
    "    # масштабирование данных\n",
    "    X_scaler = RobustScaler()\n",
    "    y_scaler = RobustScaler()\n",
    "\n",
    "    y_train_norm = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "    \n",
    "    X_train_norm = X_scaler.fit_transform(X_train.drop(non_scaling_features, axis = 1))\n",
    "    X_train_norm = np.c_[X_train_norm, X_train[non_scaling_features]]\n",
    "    \n",
    "    model = HuberRegressor()\n",
    "    # обучение модели\n",
    "    model.fit(X_train_norm, y_train_norm)\n",
    "    \n",
    "    # сохранение модели и скейлеров\n",
    "    joblib.dump(model, os.path.join(models_dir, f'model_{i}.joblib'))\n",
    "    joblib.dump(X_scaler, os.path.join(models_dir, f'X_scaler_{i}.joblib'))\n",
    "    joblib.dump(y_scaler, os.path.join(models_dir, f'y_scaler_{i}.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "541b7c98-d49f-4f98-b67b-5d0c49779292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_without_lag = create_features_without_lag(df_Q[id], df_T[id], df_holidays, id, trig = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b396902f-614d-4c41-824c-f7d02cd989b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'df' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m): \u001b[38;5;66;03m# прогноз на 10 суток с сохранением 120 моделей (по одной на каждую двухчасовку)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     train_model_and_save(df_features_without_lag, \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m, i \u001b[38;5;241m=\u001b[39m i, date_start \u001b[38;5;241m=\u001b[39m pred_start_date, models_dir \u001b[38;5;241m=\u001b[39m models_dir)\n\u001b[1;32m      3\u001b[0m prin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mОбучение завершено\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_features_without_lag)\n",
      "Cell \u001b[0;32mIn[127], line 33\u001b[0m, in \u001b[0;36mtrain_model_and_save\u001b[0;34m(df_features_without_lag, id, i, date_start, models_dir)\u001b[0m\n\u001b[1;32m     30\u001b[0m date_target \u001b[38;5;241m=\u001b[39m date_start \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# экстракция признаков из временного ряда\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m df_features \u001b[38;5;241m=\u001b[39m create_features_lag(df_features_without_lag, i) \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# определение тренировочного набора\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_features\u001b[38;5;241m.\u001b[39mloc[df_features\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m date_target])\n",
      "Cell \u001b[0;32mIn[117], line 101\u001b[0m, in \u001b[0;36mcreate_features_lag\u001b[0;34m(df_features_without_lag, lag)\u001b[0m\n\u001b[1;32m     99\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_features_without_lag\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    100\u001b[0m     df_features_without_lag \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'df' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3): # прогноз на 10 суток с сохранением 120 моделей (по одной на каждую двухчасовку)\n",
    "    train_model_and_save(df_features_without_lag, id = id, i = i, date_start = pred_start_date, models_dir = models_dir)\n",
    "prin('Обучение завершено')\n",
    "print(df_features_without_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cd41d-0a5c-4f63-a9d1-ea975ca3d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_pred.train_model_and_save(df_features_without_lag, id = id, i = i, date_start = pred_start_date, models_dir = models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "311e2368-f297-4e7c-b1ef-4f8cec9fd0d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'df' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_features_lag(df_features_without_lag, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[117], line 101\u001b[0m, in \u001b[0;36mcreate_features_lag\u001b[0;34m(df_features_without_lag, lag)\u001b[0m\n\u001b[1;32m     99\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_features_without_lag\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    100\u001b[0m     df_features_without_lag \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'df' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "create_features_lag(df_features_without_lag, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed9fe382-6004-4f8a-a43e-b996332abc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_predict(df_features_without_lag, id = id, i = i, date_start = pred_start_date, models_dir = models_dir):\n",
    "    trig = False\n",
    "    if trig == False:\n",
    "        non_scaling_features = ['holiday', \n",
    "                                'month_1', 'month_2', 'month_3',\n",
    "           'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
    "           'month_10', 'month_11', \n",
    "                            'day_of_week_1', 'day_of_week_2',\n",
    "           'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6',\n",
    "           'Hour_3', 'Hour_5', 'Hour_7', 'Hour_9', 'Hour_11', 'Hour_13',\n",
    "           'Hour_15', 'Hour_17', 'Hour_19', 'Hour_21', 'Hour_23']\n",
    "    if trig == True:\n",
    "        non_scaling_features = ['holiday','month_sin','month_cos','dow_sin','dow_cos','hour_sin','hour_cos']\n",
    "\n",
    "    #scaling_features = list(set(list(df_features.columns)) - set(non_scaling_features))\n",
    "    date_target = date_start - pd.Timedelta(hours=2)\n",
    "    \n",
    "    # загрузка модели и скейлеров\n",
    "    model_ = joblib.load(os.path.join(models_dir, f'model_{i}.joblib'))\n",
    "    X_scaler_ = joblib.load(os.path.join(models_dir, f'X_scaler_{i}.joblib'))\n",
    "    y_scaler_ = joblib.load(os.path.join(models_dir, f'y_scaler_{i}.joblib'))\n",
    "        \n",
    "    df_features_ = create_features.create_features(ser_Q, ser_T, df_holidays, id, i) # экстракция признаков из временного ряда\n",
    "    \n",
    "    # строка, которая на i*2 часов больше чем date_start\n",
    "    date_target = date_target + pd.Timedelta(hours=i*2)\n",
    "        \n",
    "    # определение тестового набора\n",
    "    test_ = df_features_.iloc[df_features_.index == date_target]\n",
    "    \n",
    "    y_test_ = test_['Q']\n",
    "    X_test_ = test_.drop('Q', axis = 1)\n",
    "    X_test_norm_ = X_scaler_.transform(X_test_.drop(non_scaling_features, axis=1))\n",
    "    X_test_norm_ = np.c_[X_test_norm_, X_test_[non_scaling_features]]\n",
    "    \n",
    "    # предсказание\n",
    "    y_pred_scaled_ = model_.predict(X_test_norm_)\n",
    "    y_pred_ = y_scaler_.inverse_transform(y_pred_scaled_.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    return y_pred_, date_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7d41a6a2-a59c-498e-8790-3a4209dbd1da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m load_model_and_predict(df_features_without_lag, \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, date_start \u001b[38;5;241m=\u001b[39m pred_start_date, models_dir \u001b[38;5;241m=\u001b[39m models_dir)\n",
      "Cell \u001b[0;32mIn[148], line 19\u001b[0m, in \u001b[0;36mload_model_and_predict\u001b[0;34m(df_features_without_lag, id, i, date_start, models_dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m date_target \u001b[38;5;241m=\u001b[39m date_start \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# загрузка модели и скейлеров\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model_ \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     20\u001b[0m X_scaler_ \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_scaler_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     21\u001b[0m y_scaler_ \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_scaler_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "load_model_and_predict(df_features_without_lag, id = 1, i = 2, date_start = pred_start_date, models_dir = models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "85c26bbe-aae9-498e-a32b-e92029d0aa85",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scratch/Pugachenko/for_Tomsk/pipeline/streamlit_v2/saved_models_1/X_scaler_1.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_scaler_ \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscratch/Pugachenko/for_Tomsk/pipeline/streamlit_v2/saved_models_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_scaler_1.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/envs/pugachenko/lib/python3.11/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scratch/Pugachenko/for_Tomsk/pipeline/streamlit_v2/saved_models_1/X_scaler_1.joblib'"
     ]
    }
   ],
   "source": [
    "X_scaler_ = joblib.load(os.path.join('scratch/Pugachenko/for_Tomsk/pipeline/streamlit_v2/saved_models_1', f'X_scaler_1.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb9d7c34-bb3b-452a-9508-cb095f3b7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b3ccee8-2de5-45e8-97ef-a827c4098950",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'saved_models_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f440876b-b713-4a59-a8cc-5e4af3aaab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "832531da-dbc8-42b9-b84f-eb33fa9cc1f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaler_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_scaler_(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaler_' is not defined"
     ]
    }
   ],
   "source": [
    "X_scaler_(f'{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e046d-92cc-42d6-9124-895ce19ad232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pugachenko",
   "language": "python",
   "name": "pugachenko"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
